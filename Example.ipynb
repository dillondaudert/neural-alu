{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Accumulator and ALU\n",
    "This is a simple implementation of the Neural Accumulator and Neural Arithmetic Logic Unit as a Flux layer. \n",
    "\n",
    "From the paper:\n",
    "> Here we propose two models that are able to learn to represent and manipulate numbers in a systematic\n",
    "way. The first supports the ability to accumulate quantities additively, a desirable inductive bias for\n",
    "linear extrapolation. This model forms the basis for a second model, which supports multiplicative\n",
    "extrapolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Accumulator\n",
    "The NAC consists of a special affine transformation that consists of only -1's, 0's, and 1's. This prevents the layer from rescaling the representations when mapping from input to output.\n",
    "\n",
    "This is accomplished by combining the saturating nonlinearities $tanh$ and $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{a} & = \\mathbf{Wx} \\\\ \n",
    "\\mathbf{W} &= tanh(\\mathbf{\\hat{W}}) \\odot \\sigma(\\mathbf{\\hat{M}}),\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\mathbf{\\hat{W}}$ and $\\mathbf{\\hat{M}}$ are weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of tan(x)*σ(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Accumulator\n",
    "struct NAC\n",
    "    W\n",
    "    M\n",
    "end\n",
    "\n",
    "NAC(in::Integer, out::Integer) = \n",
    "    NAC(param(randn(out, in)), param(randn(out, in)))\n",
    "\n",
    "(nac::NAC)(x) = (tanh.(nac.W) .* σ.(nac.M)) * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Arithmetic Logic Unit\n",
    "> The NALU consists of two NAC cells interpolated by a learned sigmoidal gate g, such that if the add/subtract subcell’s output value is applied with a weight of 1 (on), the multiply/divide subcell’s is 0 (off) and vice versa.  The first NAC computes the accumulation vector a, which stores results of the NALU’s addition/subtraction operations; it is computed  identically to the original NAC, (i.e., a = Wx). The second NAC operates in log space and is therefore capable of learning to multiply and divide, storing its results in m.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{y} &= \\mathbf{g} \\odot \\mathbf{a} + (1 - \\mathbf{g}) \\odot \\mathbf{m} \\\\\n",
    "\\mathbf{m} &= \\exp \\mathbf{W} (\\log (|\\mathbf{x}| + \\epsilon)), \\mathbf{g} = \\sigma(\\mathbf{Gx})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Arithmetic Logic Unit\n",
    "struct NALU\n",
    "    nacₐ :: NAC\n",
    "    nacₘ :: NAC\n",
    "    G\n",
    "end\n",
    "\n",
    "NALU(in::Integer, out::Integer) = \n",
    "    NALU(NAC(in, out), NAC(in, out), param(randn(out, in)))\n",
    "\n",
    "function (nalu::NALU)(x)\n",
    "    # gate\n",
    "    g = σ.(nalu.G*x)\n",
    "    \n",
    "    # addition\n",
    "    a = nalu.nacₐ(x)\n",
    "    \n",
    "    # multiplication\n",
    "    m = exp.(nalu.nacₘ(log.(abs.(x) .+ eps())))\n",
    "    \n",
    "    # nalu\n",
    "    return g .* a + (1 .- g) .* m\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
